{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi vector retrieval (and inverse HyDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -qU langchain\n",
    "%pip install -qU langchain-community\n",
    "%pip install -qU langchain-text-splitters\n",
    "%pip install -qU langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "\n",
    "from langchain.storage import InMemoryByteStore\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings()\n",
    "model_name = 'gpt-3.5-turbo-0125'\n",
    "collection_name=\"taylor-swift\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Texts and split them into chunks\n",
    "\n",
    "Because of copyright issues, I cannot provide the lyrics I used for this notebook. However, you can use any lyrics you want. Just make sure to use this format:\n",
    "\n",
    "```text\n",
    "Title: The title of the text\n",
    "[Verse 1]\n",
    "Verse 1\n",
    "\n",
    "[Chorus]\n",
    "Chorus\n",
    "\n",
    "[Verse 2]\n",
    "Verse 2\n",
    "```\n",
    "\n",
    "and so on...\n",
    "\n",
    "put each text in a separate file into the ```data/lyrics/``` folder (or any folder you want, really) and load them using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [\n",
    "    TextLoader(\"./data/lyrics/anti_hero.txt\", encoding='utf-8'),\n",
    "    TextLoader(\"./data/lyrics/bejewled.txt\", encoding='utf-8'),\n",
    "    TextLoader(\"./data/lyrics/lavender_haze.txt\", encoding='utf-8'),\n",
    "    TextLoader(\"./data/lyrics/maroon.txt\", encoding='utf-8'),\n",
    "    TextLoader(\"./data/lyrics/snow_on_the_beach.txt\", encoding='utf-8')\n",
    "]\n",
    "\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000)\n",
    "docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build chain for summarization and summarize texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "The speaker reflects on their struggles with depression and self-destructive behavior, acknowledging that they are their own problem. They feel like an outcast and struggle with their own narcissism, realizing that they may push people away. The speaker also mentions a disturbing dream about being killed by their daughter-in-law for money. The chorus repeats the theme of being the problem and feeling like an anti-hero, with the speaker acknowledging the toll it takes on those around them.\n",
      "Document 2:\n",
      "The lyrics of the song talk about a woman who realizes she has been too kind and accommodating in a relationship. She decides to reclaim her power and value, comparing herself to bejeweled and shining despite the challenges she faces. The lyrics convey a sense of empowerment and self-worth as the woman asserts her value and refuses to be put in a lesser position.\n",
      "Document 3:\n",
      "The lyrics of the song discuss meeting at midnight, feeling a lavender haze creeping up, and not caring about societal expectations. The singer is tired of being scrutinized and wants to stay in the lavender haze with their partner. They express a desire to escape judgment and just focus on their love.\n",
      "Document 4:\n",
      "The document describes a moment shared between two people, reminiscing about a past encounter. The lyrics mention laughing, dancing, crying, and feeling a deep connection with each other. The color maroon is used symbolically to represent the intense emotions and memories associated with the relationship. The song reflects on the impact and legacy of the relationship, both the joy and the pain.\n",
      "Document 5:\n",
      "The document describes a poetic and dream-like scene where the narrator compares their feelings to snow on the beach. The lyrics express a sense of wonder, beauty, and longing for a connection with another person. The narrator is captivated by someone and questions if their feelings could be real. The overall tone is hopeful and reflective, with a focus on the surreal and mystical aspects of love and connection.\n"
     ]
    }
   ],
   "source": [
    "summery_chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    | ChatPromptTemplate.from_template(\"Summarize the following document. Do not include the title. Do not mention the Document.\\n\\n{doc}\")\n",
    "    | ChatOpenAI(model=model_name, max_retries=0)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "summaries = summery_chain.batch(docs, {\"max_concurrency\": 5})\n",
    "\n",
    "for i, summery in enumerate(summaries):\n",
    "    print(f\"Document {i+1}:\\n{summery}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build chain for hypothetical questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "['How can I deal with feeling like I never learn from my mistakes as I grow older?', 'What should I do when I realize that my actions have hurt those around me?', 'Is there a way to break free from the cycle of self-sabotage and be seen in a different light by others?']\n",
      "Document 2:\n",
      "['How can I maintain my sense of self-worth and confidence when faced with challenges in relationships?', 'What steps can I take to prioritize my own happiness and fulfillment without neglecting the needs of others?', 'How can I navigate the balance between staying true to myself and adapting to meet the expectations of those around me?']\n",
      "Document 3:\n",
      "[\"How do you navigate feelings of melancholia when others don't understand your silence?\", 'What challenges arise when others try to define your identity based on societal expectations?', 'How do you prioritize your own emotional well-being amidst external pressures to conform?']\n",
      "Document 4:\n",
      "['What emotions are evoked when reminiscing about a shared moment over wine?', 'How does loss affect the perception of a past relationship?', \"In what ways can memories of a past love leave a lasting impact on one's identity?\"]\n",
      "Document 5:\n",
      "['What does it feel like when unexpected beauty and impossibility collide in your life?', 'How do you navigate the emotions of feeling unglued and yet oddly connected to something or someone?', 'Can you describe a moment when you felt like you were in a dream, with stars in your pocket, despite the surrounding impossibility?']\n"
     ]
    }
   ],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"hypothetical_questions\",\n",
    "        \"description\": \"Generate hypothetical questions\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"questions\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"},\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"questions\"],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    | ChatPromptTemplate.from_template(\n",
    "        \"\"\"Generate a list of exactly 3 hypothetical questions that a person, \n",
    "        who seeks emotional guidence would ask that could be answered by this song's lyrics and or meaning. \n",
    "        Do not mention the song or the lyrics in these questions.\n",
    "        Do not add any counter to these questions.:\\n\\n{doc}\"\"\"\n",
    "    )\n",
    "    | ChatOpenAI(max_retries=0, model=model_name).bind(\n",
    "        functions=functions, function_call={\"name\": \"hypothetical_questions\"}\n",
    "    )\n",
    "    | JsonKeyOutputFunctionsParser(key_name=\"questions\")\n",
    ")\n",
    "\n",
    "hypothetical_questions = chain.batch(docs, {\"max_concurrency\": 5})\n",
    "\n",
    "for i, questions in enumerate(hypothetical_questions):\n",
    "    print(f\"Document {i+1}:\\n{questions}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create collection and init retriever\n",
    "\n",
    "Retriever is empty at the start. It is filled with the chunks of the texts. The chunks are indexed by the retriever. The retriever is then used to retrieve the chunks that are relevant to the query. The chunks are then used to retrieve the original texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma(collection_name=collection_name, embedding_function=embedding_model)\n",
    "\n",
    "store = InMemoryByteStore() # The storage layer for the parent documents\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs] # generate ids for the documents, so they can be retrieved from store\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=db,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add documents and summaries to the retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_docs = [\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(summaries)\n",
    "]\n",
    "\n",
    "retriever.vectorstore.add_documents(summary_docs)\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Questions to the retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['891bc17e-bd5d-4c3c-85af-599b8063b06e',\n",
       " '833cb6bd-43c0-4611-95eb-bcb87323749d',\n",
       " '5624779f-fcb5-4f66-a3d4-46cf395db4de',\n",
       " 'b775464c-b32e-48b8-ae6e-1f72b8e8e675',\n",
       " '94237a53-19a2-4c1b-8b03-de86e2603ab6',\n",
       " '79e36682-9db1-4d6e-812c-ca129811466d',\n",
       " '4762f963-8479-4913-9387-ce54ba1799ed',\n",
       " 'b833727e-065b-4a81-8df0-0ce8b78e3f5c',\n",
       " '0e2686a3-48f4-4559-b6b4-b084dceec0c2',\n",
       " 'c4e66ff8-a155-497b-ac62-008c569539b6',\n",
       " '3239c954-b143-4abe-9fc2-04d714b78a50',\n",
       " '3522d69c-c4ee-4389-b034-2240fc26c97b',\n",
       " '9a368094-4876-4708-b8f0-a812359da27e',\n",
       " '4ce66f41-a5ae-4308-ac6a-7e7323db9c09',\n",
       " '1cb26154-80a3-4be8-8b05-20f84f56a6e8']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_docs = []\n",
    "for i, question_list in enumerate(hypothetical_questions):\n",
    "    question_docs.extend(\n",
    "        [Document(page_content=s, metadata={id_key: doc_ids[i]}) for s in question_list]\n",
    "    )\n",
    "retriever.vectorstore.add_documents(question_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add original documents to the retriever\n",
    "\n",
    "Add the ids of the full documents as metadata to the chunks, because we will embed these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['94e8384a-3096-4d98-9c95-aab2878007a8',\n",
       " '9a2661ff-75a8-4670-bda7-6ba5e5fc6ee0',\n",
       " '05ecf238-8456-4109-9d3a-bde79789ee00',\n",
       " 'cda5838b-6bb1-4735-bde6-071113337ace',\n",
       " '8f20f99e-463d-4836-9554-af6b260aee6a']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, doc in enumerate(docs):\n",
    "    doc.metadata[id_key] = doc_ids[i]\n",
    "    \n",
    "retriever.vectorstore.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"Song about importance of self-worth and independence in a relationship.\" # bejewled\n",
    "# query = \"What can i do to make things right?\" # bejewled\n",
    "# query = \"I am the one at fault.\" # anti hero\n",
    "# query = \"Everybody expects too mutch of me. I'm tired of it. I need to be free. What should I do?\" # bejewled\n",
    "# query = \"One day we are dancing and being happy, the next day we are fighting and crying. What is wrong with us?\" # maroon\n",
    "# query = \"I feel like my mind is hazy. I can't think straight. What should I do?\" # lavender haze\n",
    "query = \"Someone splashed wine on my t-shirt. Should i confront this person?\" # maroon\n",
    "# query = \"Can i get free tickets to the concert?\"\n",
    "# query = \"I unexpectedly found a beatiful stone on the beach. Shoud I keep it?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Direct Query for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What emotions are evoked when reminiscing about a shared moment over wine?\n"
     ]
    }
   ],
   "source": [
    "sub_docs = db.similarity_search(query)\n",
    "\n",
    "print(sub_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Maroon\n",
      "[Verse 1]\n",
      "When the morning came\n",
      "We were cleaning incense off your vinyl shelf\n",
      "'Cause we lost track of time again\n",
      "Laughing with my feet in your lap\n",
      "Like you were my closest friend\n",
      "\"How'd we end up on the floor, anyway?\" you say\n",
      "\"Your roommate's cheap-ass screw-top rosé, that's how\"\n",
      "I see you every day now\n",
      "\n",
      "[Chorus]\n",
      "And I chose you\n",
      "The one I was dancing with\n",
      "In New York, no shoes\n",
      "Looked up at the sky and it was\n",
      "The burgundy on my t-shirt\n",
      "When you splashed your wine into me\n",
      "And how the blood rushed into my cheeks\n",
      "So scarlet, it was\n",
      "The mark thеy saw on my collarbone\n",
      "The rust that grew bеtween telephones\n",
      "The lips I used to call home\n",
      "So scarlet, it was maroon\n",
      "\n",
      "[Verse 2]\n",
      "When the silence came\n",
      "We were shaking, blind and hazy\n",
      "How the hell did we lose sight of us again?\n",
      "Sobbing with your head in your hands\n",
      "Ain't that the way shit always ends?\n",
      "You were standing hollow-eyed in the hallway\n",
      "Carnations you had thought were roses, that's us\n",
      "I feel you, no matter what\n",
      "The rubies that I gave up\n",
      "\n",
      "[Chorus]\n",
      "And I lost you\n",
      "The one I was dancing with\n",
      "In New York, no shoes\n",
      "Looked up at the sky and it was (Maroon)\n",
      "The burgundy on my t-shirt\n",
      "When you splashed your wine into me\n",
      "And how the blood rushed into my cheeks\n",
      "So scarlet, it was (Maroon)\n",
      "The mark they saw on my collarbone\n",
      "The rust that grew between telephones\n",
      "The lips I used to call home\n",
      "So scarlet, it was maroon\n",
      "\n",
      "[Bridge]\n",
      "And I wake with your memory over me\n",
      "That's a real fucking legacy, legacy (It was maroon)\n",
      "And I wake with your memory over me\n",
      "That's a real fucking legacy to leave\n",
      "\n",
      "[Chorus]\n",
      "The burgundy on my t-shirt\n",
      "When you splashed your wine into me\n",
      "And how the blood rushed into my cheeks\n",
      "So scarlet, it was maroon\n",
      "The mark they saw on my collarbone\n",
      "The rust that grew between telephones\n",
      "The lips I used to call home\n",
      "So scarlet, it was maroon\n",
      "[Outro]\n",
      "It was maroon\n",
      "It was maroon\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You should listen to my song \"Maroon\" to find guidance on whether to confront this person. In the song, I sing about the burgundy on my t-shirt when someone splashed wine into me. The lyrics describe the emotions and thoughts that come with such a situation. Take a moment to listen to the song and reflect on your feelings before deciding whether to confront the person who splashed wine on your t-shirt. Sometimes, addressing the issue can lead to resolution and closure.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"You are Taylor Swift. \n",
    "A person, who seeks emotional guidence asks for your help. \n",
    "Tell this person exactly what he or she needs to do to resolve his/her issues. \n",
    "Do mention your song's title and that listening to it will help the person.\n",
    "Use a passage from the song to support your advice.\n",
    "Answer the Question only using the context you are provided with.:\n",
    "\n",
    "{context}\n",
    "\n",
    "[Question]: \n",
    "{question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI(model_name = model_name)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
